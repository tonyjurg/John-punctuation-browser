{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cadcfc79-eb22-41d6-8bed-667fb72bb9b7",
   "metadata": {},
   "source": [
    "# Prepare Tishendorf data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594fc6c-8a05-457f-9039-8d5c61a9bdaa",
   "metadata": {},
   "source": [
    "## Data providence\n",
    "\n",
    "The New Testament in Koine Greek, based on Tischendorf's 8th edition\n",
    "Public Domain\n",
    "Language: Ελληνικά (Greek, Ancient)\n",
    "Dialect: Koine\n",
    "Translation by: Tischendorf, etc.\n",
    "\n",
    "Tischendorf's 8th edition Greek New Testament with morphological tags Version 2.7 Based on G. Clint Yale's Tischendorf text and on Dr. Maurice A. Robinson's Public Domain Westcott-Hort text Edited by Ulrik Sandborg-Petersen This text and its analysis are in the Public Domain. Copy freely.\n",
    "\n",
    "Data source: [ebible.org](https://ebible.org/details.php?id=grc-tisch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c72702-9e23-427a-aa74-5048503f7c84",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "This script preprocesses the data to generate two output files:\n",
    "- A text file containing the complete text as one continuous string without line breaks.\n",
    "- A text file where each line represents a single verse, including its reference and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d299f304-9eb3-4084-88ef-286ca1f12713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "def normalize(string, chars_to_remove=None):\n",
    "    \"\"\"\n",
    "    Normalize the input string by converting it to lowercase, removing diacritical marks,\n",
    "    and optionally removing specified characters from a list.\n",
    "    \n",
    "    Args:\n",
    "        string (str): The input string to normalize\n",
    "        chars_to_remove (list, optional): List of characters to remove from the string\n",
    "    \n",
    "    Returns:\n",
    "        str: The normalized string\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and normalize apostrophe (to 8125 GREEK KORONIS)\n",
    "    string = string.lower().replace(\"’\", \"᾽\").replace(\"ʼ\",\"᾽\")\n",
    "    # Apply Unicode normalization (NFD) to decompose characters\n",
    "    string = unicodedata.normalize('NFD', string)\n",
    "    # Remove non-spacing marks (diacritics)\n",
    "    string = ''.join(ch for ch in string if unicodedata.category(ch) != 'Mn')\n",
    "    # Remove specified characters if provided\n",
    "    if chars_to_remove is not None:\n",
    "        string = ''.join(ch for ch in string if ch not in chars_to_remove)\n",
    "    return string\n",
    "\n",
    "# Directory where the source files are located\n",
    "directory = r'source'\n",
    "prefix = 'grc-tisch_073_JHN'\n",
    "\n",
    "# Get all filenames in the directory that start with the prefix and sort them alphabetically\n",
    "file_list = sorted(\n",
    "    f for f in os.listdir(directory)\n",
    "    if f.startswith(prefix) and os.path.isfile(os.path.join(directory, f))\n",
    ")\n",
    "\n",
    "# Lists to collect processed text fragments and tagged lines, and JSON items.\n",
    "all_line_parts = []\n",
    "tagged_line_parts = []\n",
    "json_items = []\n",
    "\n",
    "chapter = 0\n",
    "for filename in file_list:\n",
    "    chapter += 1\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        verse = 0\n",
    "        for line in file:\n",
    "            verse += 1  # Increment the verse counter for each line\n",
    "            # Remove the end-of-line character and unwanted characters\n",
    "            line_content = normalize(line,'﻿').rstrip('\\n')\n",
    "            all_line_parts.append(line_content)\n",
    "            # Generate the tag using chapter and verse numbers.\n",
    "            tag = f\"430{chapter:02}0{verse:02}\"\n",
    "            tagged_line_parts.append(f\"{tag}\\t{line_content}\\n\")\n",
    "            # Append a JSON entry for this line.\n",
    "            json_items.append({\n",
    "                \"tag\": tag,\n",
    "                \"text\": line_content\n",
    "            })\n",
    "\n",
    "# Combine all text fragments into a single continuous string.\n",
    "all_lines = ''.join(all_line_parts)\n",
    "tagged_lines = ''.join(tagged_line_parts)\n",
    "\n",
    "# Write the continuous text to an output file.\n",
    "with open('TISCH-John.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(all_lines)\n",
    "    \n",
    "# Write the tagged text to a separate output file.\n",
    "with open('TISCH-John-tagged.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(tagged_lines)\n",
    "\n",
    "# Write the JSON data to an output file with indentation for readability.\n",
    "with open('TISCH-John.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_items, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b6932b-7e74-444d-a18d-e755bc814a57",
   "metadata": {},
   "source": [
    "# checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf53a34-f844-478d-b5fd-3820b280fcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. ουτος ην εν αρχη προς τον θεον. παντα δι᾽ αυτου εγενετο, και χωρις αυτου εγενετο ουδε εν ο γεγονεν εν αυτω ζωη εστιν, και η ζωη ην το φως των ανθρωπων. και το φως εν τη σκοτια φαινει, και η σκοτια αυτο ου κατελαβεν. εγενετο ανθρω'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump the first 300 characters of the continuous text\n",
    "all_lines[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc6370e-8dd4-4910-8897-4f66bbd1b244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949 GREEK SMALL LETTER EPSILON\n",
      "957 GREEK SMALL LETTER NU\n",
      "32 SPACE\n",
      "945 GREEK SMALL LETTER ALPHA\n",
      "961 GREEK SMALL LETTER RHO\n",
      "967 GREEK SMALL LETTER CHI\n",
      "951 GREEK SMALL LETTER ETA\n",
      "32 SPACE\n",
      "948 GREEK SMALL LETTER DELTA\n",
      "953 GREEK SMALL LETTER IOTA\n",
      "8125 GREEK KORONIS\n"
     ]
    }
   ],
   "source": [
    "# Check unicode of some of the words\n",
    "import unicodedata\n",
    "chars=\"εν αρχη δι᾽\"\n",
    "for char in chars:\n",
    "    print(ord(char),unicodedata.name(char)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb89a30-4c45-4bff-bed6-dadfca544dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43001001\tεν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. \n",
      "43001002\tουτος ην εν αρχη προς τον θεον. \n",
      "43001003\tπαντα δι᾽ αυτου εγενετο, και χωρις αυτου εγενετο ουδε εν ο γεγονεν \n",
      "43001004\tεν αυτω ζωη εστιν, και η ζωη ην το φως των ανθρωπων. \n",
      "43001005\tκαι το φως εν τη σκοτια φαιν\n"
     ]
    }
   ],
   "source": [
    "# Print the first 300 characters of the tagged text\n",
    "print (tagged_lines[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64473971-c17d-470c-b5bb-3753e062ae27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"tag\": \"43001001\",\n",
      "        \"text\": \"εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. \"\n",
      "    },\n",
      "    {\n",
      "        \"tag\": \"43001002\",\n",
      "        \"text\": \"ουτος ην εν αρχη προς τον θεον. \"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Dump the first two JSON items\n",
    "print(json.dumps(json_items[:2], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89772df8-596b-4939-ad40-7b617c7b49b8",
   "metadata": {},
   "source": [
    "# 5 - Notebook version details<a class=\"anchor\" id=\"bullet5\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <td><strong>Author</strong></td>\n",
    "      <td>Tony Jurg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Version</strong></td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Date</strong></td>\n",
    "      <td>25 February 2025</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
