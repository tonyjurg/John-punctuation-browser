{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1352e2f3-c3df-4193-815b-62ad0af615e1",
   "metadata": {},
   "source": [
    "# Prepare Text-Critical Greek New Testament data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327dbcf7-a0dc-46af-9d32-df4e68d9f4e3",
   "metadata": {},
   "source": [
    "https://ebible.org/details.php?id=grctcgnt\n",
    "\n",
    "The Text-Critical Greek New Testament is based upon The New Testament in the Original Greek: Byzantine Textform 2018, compiled and arranged by Maurice A. Robinson and William G. Pierpont."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0d2fa-6605-488e-a5cb-0e45d3c86afa",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "This script preprocesses the data to generate two output files:\n",
    "- A text file containing the complete text as one continuous string without line breaks.\n",
    "- A text file where each line represents a single verse, including its reference and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854c2330-8e81-4633-b384-2c653a1decee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import json\n",
    "from itertools import islice  # Import islice to skip lines efficiently\n",
    "\n",
    "def normalize(string, chars_to_remove=None):\n",
    "    \"\"\"\n",
    "    Normalize the input string by converting it to lowercase, removing diacritical marks,\n",
    "    and optionally removing specified characters from a list.\n",
    "    \n",
    "    Args:\n",
    "        string (str): The input string to normalize\n",
    "        chars_to_remove (list, optional): List of characters to remove from the string\n",
    "    \n",
    "    Returns:\n",
    "        str: The normalized string\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and normalize apostrophe (to 8125 GREEK KORONIS)\n",
    "    string = string.lower().replace(\"’\", \"᾽\").replace(\"ʼ\",\"᾽\")\n",
    "    # Apply Unicode normalization (NFD) to decompose characters\n",
    "    string = unicodedata.normalize('NFD', string)\n",
    "    # Remove non-spacing marks (diacritics)\n",
    "    string = ''.join(ch for ch in string if unicodedata.category(ch) != 'Mn')\n",
    "    # Remove specified characters if provided\n",
    "    if chars_to_remove is not None:\n",
    "        string = ''.join(ch for ch in string if ch not in chars_to_remove)\n",
    "    return string\n",
    "    \n",
    "# Define the directory where source files are located and the filename prefix to filter by.\n",
    "directory = r'source'\n",
    "prefix = 'grctcgnt_073_JHN'\n",
    "\n",
    "# Get all filenames in the directory that start with the prefix and sort them alphabetically\n",
    "file_list = sorted(\n",
    "    f for f in os.listdir(directory)\n",
    "    if f.startswith(prefix) and os.path.isfile(os.path.join(directory, f))\n",
    ")\n",
    "\n",
    "# Initialize lists to collect text fragments and tagged lines, and JSON items.\n",
    "all_line_parts = []\n",
    "tagged_line_parts = []\n",
    "json_items = []\n",
    "\n",
    "# Process each file while automatically tracking chapter numbers (starting at 1)\n",
    "for chapter, filename in enumerate(file_list, start=1):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Skip the first two lines of the file using islice.\n",
    "        # Process the remaining lines, with verse numbering starting at 1.\n",
    "        for verse, line in enumerate(islice(file, 2, None), start=1):\n",
    "            # Remove the newline character and any unwanted special characters and normalize\n",
    "            line_content = normalize(line,'﻿').rstrip('\\n')\n",
    "            \n",
    "            # Collect the cleaned line.\n",
    "            all_line_parts.append(line_content)\n",
    "            \n",
    "            # Generate the tagged line with formatted chapter and verse numbers.\n",
    "            tag = f\"43{chapter:03}{verse:03}\"\n",
    "            tagged_line = f\"{tag}\\t{line_content}\\n\"\n",
    "            tagged_line_parts.append(tagged_line)\n",
    "\n",
    "            # Append a JSON item for this line.\n",
    "            json_items.append({\n",
    "                \"tag\": tag,\n",
    "                \"text\": line_content\n",
    "            })\n",
    "\n",
    "# Combine all text fragments into a single continuous string.\n",
    "all_lines = ''.join(all_line_parts)\n",
    "\n",
    "# Join all tagged lines, ensuring each is on a new line, with a final newline at the end.\n",
    "tagged_lines = ''.join(tagged_line_parts)\n",
    "\n",
    "# Write the output to files\n",
    "with open('TCGNT-John.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\".join(all_lines))\n",
    "\n",
    "with open('TCGNT-John-tagged.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\".join(tagged_lines))\n",
    "\n",
    "# Write the JSON data to an output file with indentation for readability.\n",
    "with open('TCGNT-John.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_items, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf19974-91f1-42df-a03c-54ca8cc9e4cb",
   "metadata": {},
   "source": [
    "# checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72c0b81-a98a-4136-9690-aaf6713fba87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. ουτος ην εν αρχη προς τον θεον. παντα δι᾽ αυτου εγενετο, και χωρις αυτου εγενετο ουδε εν ο γεγονεν. εν αυτω ζωη ην, και η ζωη ην το φως των ανθρωπων, και το φως εν τη σκοτια φαινει, και η σκοτια αυτο ου κατελαβεν. εγενετο ανθρωπο'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump the first 300 characters of the continuous text\n",
    "all_lines[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6cf23ec-49f8-4fc7-a1a4-51663ba3e74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949 GREEK SMALL LETTER EPSILON\n",
      "957 GREEK SMALL LETTER NU\n",
      "32 SPACE\n",
      "945 GREEK SMALL LETTER ALPHA\n",
      "961 GREEK SMALL LETTER RHO\n",
      "967 GREEK SMALL LETTER CHI\n",
      "951 GREEK SMALL LETTER ETA\n",
      "32 SPACE\n",
      "948 GREEK SMALL LETTER DELTA\n",
      "953 GREEK SMALL LETTER IOTA\n",
      "8125 GREEK KORONIS\n"
     ]
    }
   ],
   "source": [
    "# Check unicode of some of the words\n",
    "import unicodedata\n",
    "chars=\"εν αρχη δι᾽\"\n",
    "for char in chars:\n",
    "    print(ord(char),unicodedata.name(char)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cce17c-9af5-42c2-837e-61bb7b13dd02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43001001\tεν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. \n",
      "43001002\tουτος ην εν αρχη προς τον θεον. \n",
      "43001003\tπαντα δι᾽ αυτου εγενετο, και χωρις αυτου εγενετο ουδε εν ο γεγονεν. \n",
      "43001004\tεν αυτω ζωη ην, και η ζωη ην το φως των ανθρωπων, \n",
      "43001005\tκαι το φως εν τη σκοτια φαινει\n"
     ]
    }
   ],
   "source": [
    "# Print the first 300 characters of the tagged text\n",
    "print (tagged_lines[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70cb0340-cfdc-4f5f-8586-e94f6ad3b035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"tag\": \"43001001\",\n",
      "        \"text\": \"εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. \"\n",
      "    },\n",
      "    {\n",
      "        \"tag\": \"43001002\",\n",
      "        \"text\": \"ουτος ην εν αρχη προς τον θεον. \"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Dump the first two JSON items\n",
    "print(json.dumps(json_items[:2], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cf41ae-f4fd-4ce4-a4c2-e268bd8a81c4",
   "metadata": {},
   "source": [
    "# 5 - Notebook version details<a class=\"anchor\" id=\"bullet5\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <td><strong>Author</strong></td>\n",
    "      <td>Tony Jurg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Version</strong></td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Date</strong></td>\n",
    "      <td>25 February 2025</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
