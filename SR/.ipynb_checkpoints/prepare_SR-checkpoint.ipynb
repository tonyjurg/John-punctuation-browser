{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575728d8-4e30-406d-8f4a-411e7194c00f",
   "metadata": {},
   "source": [
    "# Prepare SR data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fec86-0d7d-45f7-8135-f603d8f63df1",
   "metadata": {},
   "source": [
    "## Data Provenance\n",
    "\n",
    "Created and provided by the [Center for New Testament Restoration](https://greekcntr.org/home/index.htm).\n",
    "\n",
    "Licence: [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/legalcode.en).\n",
    "\n",
    "Data source: [Statistical Restoration Greek New Testament (GitHub)](https://github.com/Center-for-New-Testament-Restoration/SR)\n",
    "\n",
    "Bunning, Alan, ed. *Statistical Restoration Greek New Testament.* Center for New Testament Restoration. 2022.\n",
    "\n",
    "[SR Introduction.pdf](https://github.com/Center-for-New-Testament-Restoration/SR/blob/main/SR%20Introduction.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6f68f-0d3b-4dfd-a0a9-728476065bec",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "This script preprocesses the data to generate two output files:\n",
    "- A text file containing the complete text as one continuous string without line breaks.\n",
    "- A text file where each line represents a single verse, including its reference and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f28f6f37-d2a3-4b8c-86f6-ee48fc4f171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import json\n",
    "\n",
    "def normalize(string, chars_to_remove=None):\n",
    "    \"\"\"\n",
    "    Normalize the input string by converting it to lowercase, removing diacritical marks,\n",
    "    and optionally removing specified characters from a list.\n",
    "    \n",
    "    Args:\n",
    "        string (str): The input string to normalize\n",
    "        chars_to_remove (list, optional): List of characters to remove from the string\n",
    "    \n",
    "    Returns:\n",
    "        str: The normalized string\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and normalize apostrophe (to 8125 GREEK KORONIS)\n",
    "    string = string.lower().replace(\"’\", \"᾽\").replace(\"ʼ\",\"᾽\")\n",
    "    # Apply Unicode normalization (NFD) to decompose characters\n",
    "    string = unicodedata.normalize('NFD', string)\n",
    "    # Remove non-spacing marks (diacritics)\n",
    "    string = ''.join(ch for ch in string if unicodedata.category(ch) != 'Mn')\n",
    "    # Remove specified characters if provided\n",
    "    if chars_to_remove is not None:\n",
    "        string = ''.join(ch for ch in string if ch not in chars_to_remove)\n",
    "    return string\n",
    "\n",
    "# Location where the source file is located\n",
    "file_path = r'source/SR-John.txt'\n",
    "\n",
    "# Lists to collect processed text fragments and tagged lines, and JSON items.\n",
    "all_lines_parts = []\n",
    "tagged_lines_parts = []\n",
    "json_items = []\n",
    "\n",
    "# Open the source file for reading using UTF-8 encoding.\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        # Split the line into tag and text\n",
    "        text = normalize(line[8:],'¶˚').rstrip('\\n')\n",
    "        tag = line[:8]\n",
    "        all_lines_parts.append(text)\n",
    "        # Format the tagged line and add a newline.\n",
    "        tagged_lines_parts.append(f\"{tag}\\t{text}\\n\")\n",
    "        # Create a JSON entry for this line.\n",
    "        json_items.append({\n",
    "            \"tag\": tag,\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "# Join all parts into single strings.\n",
    "all_lines = ''.join(all_lines_parts)\n",
    "tagged_lines = ''.join(tagged_lines_parts)\n",
    "\n",
    "# Write the continuous text to the output file.\n",
    "with open('SR-John.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(all_lines)\n",
    "\n",
    "# Write the tagged text to a separate output file.\n",
    "with open('SR-John-tagged.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(tagged_lines)\n",
    "\n",
    "# Write the JSON data to an output file with indentation for readability.\n",
    "with open('SR-John.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_items, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcf4bb-4a9c-4849-925e-1250cc796540",
   "metadata": {},
   "source": [
    "# checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39614e16-d939-4863-a2d4-69376b109279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος. ουτος ην εν αρχη προς τον θεον. παντα δι᾽ αυτου εγενετο, και χωρις αυτου εγενετο ουδε εν ο γεγονεν. εν αυτω ζωη ην, και η ζωη ην το φως των ανθρωπων. και το φως εν τη σκοτια φαινει, και η σκοτια αυτο ου κατελαβεν. εγενετο ανθρωπ'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump the first 300 characters of the continuous text\n",
    "all_lines[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe5d398b-2967-4db7-84e0-50e023570ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949 GREEK SMALL LETTER EPSILON\n",
      "957 GREEK SMALL LETTER NU\n",
      "32 SPACE\n",
      "945 GREEK SMALL LETTER ALPHA\n",
      "961 GREEK SMALL LETTER RHO\n",
      "967 GREEK SMALL LETTER CHI\n",
      "951 GREEK SMALL LETTER ETA\n"
     ]
    }
   ],
   "source": [
    "# Check unicode of the first three words\n",
    "chars=\"εν αρχη\"\n",
    "for char in chars:\n",
    "    print(ord(char),unicodedata.name(char)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfc82dd-7a67-41cc-a08f-0ce2db7a107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43001001\t εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος.\n",
      "43001002\t ουτος ην εν αρχη προς τον θεον.\n",
      "43001003\t παντα δι᾽ αυτου εγενετο, και χωρις αυτου εγενετο ουδε εν ο γεγονεν.\n",
      "43001004\t εν αυτω ζωη ην, και η ζωη ην το φως των ανθρωπων.\n",
      "43001005\t και το φως εν τη σκοτια φαινε\n"
     ]
    }
   ],
   "source": [
    "# Print the first 300 characters of the tagged text\n",
    "print (tagged_lines[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9056f194-daf3-4edb-92a3-535b2c22cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"tag\": \"43001001\",\n",
      "        \"text\": \" εν αρχη ην ο λογος, και ο λογος ην προς τον θεον, και θεος ην ο λογος.\"\n",
      "    },\n",
      "    {\n",
      "        \"tag\": \"43001002\",\n",
      "        \"text\": \" ουτος ην εν αρχη προς τον θεον.\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Dump the first two JSON items\n",
    "print(json.dumps(json_items[:2], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449eab0a-ed00-44a0-b4de-8e4aaad38212",
   "metadata": {},
   "source": [
    "# 5 - Notebook version details<a class=\"anchor\" id=\"bullet5\"></a>\n",
    "##### [Back to ToC](#TOC)\n",
    "\n",
    "<div style=\"float: left;\">\n",
    "  <table>\n",
    "    <tr>\n",
    "      <td><strong>Author</strong></td>\n",
    "      <td>Tony Jurg</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Version</strong></td>\n",
    "      <td>1.0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td><strong>Date</strong></td>\n",
    "      <td>25 February 2025</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
